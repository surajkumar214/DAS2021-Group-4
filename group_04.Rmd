---
title: "Group_04"
author: "Suraj Kumar"
date: "17/07/2021"
output: github_document
   
number_sections: yes 
always_allow_html: true
           
fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, comment = NA)
```

```{r libraries}
#included all the necessary libraries

library(tidyverse) 
library(moderndive)
library(skimr)
library(kableExtra)
library(gridExtra)
library(GGally)
library(infer)
library(broom)
library(ggfortify)
library(jtools)
library(sjPlot)
library(AER)
library(car)

```



```{r data,echo=FALSE,eval=TRUE}
dataset4<-read.csv("/home/suraj/Desktop/stats_folder/group_04.csv")
dataset4<-dataset4%>%
  select(-Region)
dataset4[sapply(dataset4,is.character)]<-lapply(dataset4[sapply(dataset4,is.character)],as.factor)

dataset4$Electricity <-as.factor(dataset4$Electricity)
#dataset4$Number.of.bedrooms <-as.factor(dataset4$Number.of.bedrooms)

```

# Introduction {#sec:Intro}
The Philippine government conducts surveys on household income and expenditure every three years to understand the living conditions of residents. In some past studies, we found that some factors may affect the number of family members. This research studied 2122 families in Soccsksargen district and collected the data of total household income, total food expenditure, household head sex, household head age, type of household, total number of family members, house floor area, house age, number of bedrooms and electricity, the purpose is to find the relationship between the number of family members and other variables. This report focuses on a different analysis level through summaries, boxplots, and general linear model. Section consists of an exploratory data analysis of number of family members and explores the potential relationship between member numbers and other variables. Section contains the results from fitting a generalized linear model to the data, as well as the assessment of the model assumptions. Concluding remarks are given in Section .


# Exploratory Data Analysis {#sec:EDA}
```{r exp}

```

# Formal Data Analysis {#sec:FDA}

We fit a Poisson model as our response is a count variable. We have excluded Region as a covariate because there was only one factor. We will start with a model that considers all the initial impressions from the exploratory analysis. The model takes into account the interaction between log(Household.Head.Age) and Type.of.Household, log(Total.Food.Expenditure ) and Type.of.Household, and  log(Total.Household.Income) and Electricity, and  Type.of.Household  and Electricity. We have scaled Total.Food.Expenditure, Total.Household.Income, Household.Head.Age, and House.Floor.Area by taking log transformation to address the scalability issue in the design matrix. Here is the summary of the described model:- 



```{r model1}

model1 <- glm(Total.Number.of.Family.members ~ 
                Household.Head.Sex                                                   +
                
                log(Household.Head.Age)*   Type.of.Household                        +
                log(Total.Food.Expenditure ) * Type.of.Household                     +
                log(Total.Household.Income) * Type.of.Household                      +
               log(Total.Household.Income) * Electricity                            +
                Type.of.Household*Electricity                                        +
                log(House.Floor.Area)                                                +
                Number.of.bedrooms                                                   +
                House.Age                                                           
                                                 
               ,data = dataset4,family = "poisson")  # fitted the poisson model using glm
model1 %>%
  summ()

 
  
```
We can observe a lot of insignificant variables in our initial model. However, before proceeding to the wald test to check the significance of each variable, we, firstly, looked for any potential outliers and checked whether assumptions are holding.  We can notice that the deviance of the model(`r round(deviance(model1),2)`) is much less than chi-square(`r round(qchisq(df = model1$df.residual,p = 0.95),2)`). There could be a case of underdispersion wherein the estimated variance is less than the expected mean. We can interpret the coefficients in such a situation but can't rely on standard error as they are deflated. 
 
```{r plot, out.width = '68%', fig.align = "center", fig.cap = "\\label{fig:out} Outlier check", fig.pos = 'H'}
resp <-  model1 %>%
  resid(type = "pearson")
resd <- model1 %>%
  resid(type = "deviance")
p1<-  model1 %>%
  ggplot( aes(sample = resp)) + geom_point(stat = "qq", color = "#7fc97f") +
  ylab("Pearson residuals")
p2<- model1 %>%
  ggplot( aes(sample = resd)) + geom_point(stat = "qq", color = "#7fc97f") +
  ylab("Deviance residuals")
p3<- model1  %>%
  ggplot( aes(x = predict(model1, type="link"), y =resd))+
  geom_point(col = "#7fc97f") +
  ylab("Deviance residuals") + xlab("Linear predictor")
grid.arrange(p1, p2, p3, nrow = 1)  


```
We have plotted Normal_qq_plot for Pearson and deviance residuals. The purpose of such plots is to identify any point that doesn't follow the straight line. We have also plotted deviance residuals vs. the fitted value to check the independence and identify any pattern in the residuals. From above Figure \ref{fig:out}, we can notice one potential outlier at the top of the qq_plot, and presence of heavy tails. So, our next step is to identify and remove the point and again fit the model. Let's run an Outlier test:- 



```{r outlier}

 model1 %>%
  outlierTest() 
  
```
We have identified the outlier point having id 2033. However, addressing outlier is totally subjective. We try to fit the model again removing this outlier and check for the assumptions. 

```{r mod1}
dataset4 <- dataset4 %>%
    slice(-c(2033))

model1 <- glm(Total.Number.of.Family.members ~ 
                Household.Head.Sex                                                   +
                
                log(Household.Head.Age) *  Type.of.Household                         +
                log(Total.Food.Expenditure ) * Type.of.Household                     +
                log(Total.Household.Income) * Type.of.Household                      +
                log(Total.Household.Income) * Electricity                            +
                Type.of.Household * Electricity                                                         +
                log(House.Floor.Area)                                                +
                Number.of.bedrooms                                                   +
                House.Age                                                           
                                                 
               ,data = dataset4,family = "poisson") 
```

```{r plot1, out.width = '68%', fig.align = "center", fig.cap = "\\label{fig:assum} Assumptions checking", fig.pos = 'H'}
resp <-  model1 %>%
  resid(type = "pearson")
resd <- model1 %>%
  resid(type = "deviance")
p1<-  model1 %>%
  ggplot( aes(sample = resp)) + geom_point(stat = "qq", color = "#7fc97f") +
  ylab("Pearson residuals")
p2<- model1 %>%
  ggplot( aes(sample = resd)) + geom_point(stat = "qq", color = "#7fc97f") +
  ylab("Deviance residuals")
p3<- model1  %>%
  ggplot( aes(x = predict(model1, type="link"), y =resd))+
  geom_point(col = "#7fc97f") +
  ylab("Deviance residuals") + xlab("Linear predictor")
grid.arrange(p1, p2, p3, nrow = 1)  
```
From Figure \ref{fig:assum}, we can see some patterns in the residuals vs predicted value. It would be better to fit some quadratic terms in the explanatory variables. Residuals seem to be normally distributed with some heavy tails. Now, we proceed with the dispersion test as there has been some evidence of underdispersion. 

```{r plot2, out.width = '68%', fig.align = "center", fig.cap = "\\label{fig:disp} Assumptions checking", fig.pos = 'H'}
model1 %>%
 ggplot( aes(x=log(fitted(model1)), y=log((dataset4$Total.Number.of.Family.members-fitted(model1))^2)))+
  geom_point(col="#f46d43") +
  geom_abline(slope=1, intercept=0, col="#a6d96a", size=1) +
  ylab(expression((y-hat(mu))^2)) + xlab(expression(hat(mu)))
```

```{r disp}
dis <- model1 %>%
dispersiontest( trafo = 1 ,alternative = c("less"))
dis
```
The negative value of aplha (`r round(dis$estimate,2)`) is significant because the p_value for the hypothesis test is (`r round(dis$p.value,2)`). Figure \ref{fig:disp} displays the underdispersed variance. Therefore, we can't rely on Wald's test for inference in the above model.  Rather, we perform analysis with quasi-poisson model that adjusts variance for both overdispersion and underdispersion. We resort to F test and do step by step variable removal to choose the best fitting model.  



```{r drop1}
drop <- model1 %>%
drop1(test="F") %>%
  kable(caption = '\\label{tab:drop1} Performing F test on the inital model') %>%
kable_styling(latex_options = 'HOLD_position')

drop
```
In the table \ref{tab:drop1},log(Household.Head.Age):Type.of.Household, Type.of.Household:log(Total.Food.Expenditure)	 and Type.of.Household:log(Total.Household.Income) can be eliminated without significantly hurting the model's quality So, we firstly eliminate variable Type.of.Household:log(Total.Household.Income)	 and check for F test again:-
 


```{r mod3}
model2 <- glm(Total.Number.of.Family.members ~ 
                Household.Head.Sex                                                   +
                log( Household.Head.Age)*  Type.of.Household                             +
                
                log(Total.Food.Expenditure)*Type.of.Household                      +
                log(Total.Household.Income) * Electricity                            +
                Type.of.Household*    Electricity                                  +                                  
                log(House.Floor.Area)                                                +
                House.Age                                                            +
                Number.of.bedrooms                                  
               ,data = dataset4,family = "poisson")  # fitted the poisson model using glm

drop <- model2 %>%
drop1(test="F") %>%
  kable(caption = '\\label{tab:drop1} Performing F test on the inital model') %>%
kable_styling(latex_options = 'HOLD_position')

drop

 

```
The F test says that we can remove log(Household.Head.Age):Type.of.Household and. So, repeat the same process until we reach all terms are significant. 




```{r mod4}

model3 <- glm(Total.Number.of.Family.members ~ 
                Household.Head.Sex                                                   +
                log(Household.Head.Age )                              +
                log(Total.Food.Expenditure ) *Type.of.Household   +
                
                log(Total.Household.Income) * Electricity                            +
                 Type.of.Household*  Electricity                                    +
                log(House.Floor.Area)                                                +
                House.Age                                                            +
                Number.of.bedrooms                                 
                
               ,data = dataset4,family = "poisson")  # fitted the poisson model using glm

drop <- model3 %>%
drop1(test="F") %>%
  kable(caption = '\\label{tab:drop1} Performing F test on the inital model') %>%
kable_styling(latex_options = 'HOLD_position')

drop


```
Eventually, we reached to our final model that considers interactions between log(Total.Food.Expenditure):Type.of.Household , log(Total.Household.Income):Electricity, and Type.of.Household:Electricity  as significant. Now, we adjust the standard error using dispersion parameter, which is equivalent of fitting a quasipoission model.  
```{r final}
X2 <- sum(resid(model3, type = "pearson")^2)
dp <- X2 / model3$df.res
dp
model3 %>%
 summ( dispersion =dp)



```
We can see that standard error slight rises up after adjusting with the dispersion parameter, while the intercept term remains the same. Still the wald test is not very reliable, and there is no benefit of drawing confidence intervals. The expected Total.Number.of.Family.members increase by `r round(exp(0.22),2)` if the head of the family is male. Also, if the Type.of.Family is single and Type.of.HouseholdTwo or More Nonrelated Persons/Members, the expectation decrease  by factor of `r      round(exp(-1.08),2)` and `r round(exp(-7.97),2)` against the Extended family. Moreover, if log(Total.Food.Expenditure) and log(Total.Household.Income) are increase by 1 unit, the estimated count of family members may increase by `r round(exp(0.51),2)`  and `r round(exp(0.04),2)` respectively. 
log(Total.Household.Income) is insignificant might be due to Simpson's paradox effect. Beside it, if there is electricity at home, the estimated count may increase by `r round(exp(2.08),2)`. Taking about number of bedrooms,  if there is 1 more unit extra bedroom, the estimated number increases by `r   round(exp(0.03),2)`. Conversely, 1 unit increase in log(house area) and 1 year increase in house age, reduce the estimated count by `r  round(exp(-0.05),2)` and `r  round(-0.003804283 ,2)`. The effect of the head's age is insignificant. There are some other significant interactions. For instance, if the type of household is single family, and log(foodexpenditure) is increased by 1 unit, then the estimated count increment will have higher rate by `r  round(exp(0.09+0.51),2)` against Extended family. Beside it, if there is electricity, and log(income) is increased by 1 unit, the rate of increment of count increase by a factor of `r  round(exp(-0.19+ 2.08) ,2)`. Also, if the family is single and there is electricity, the count of family members is estimated to change  by `r round(exp(-1.08 +2.08 + -0.20) ,2)`. 

# Conclusions {#sec:Conc}
The number of family members has positive association with food expenditure and family income. Also, Extended family is suppose to have higher family members than single and much greater than Nonrelated Persons/Members. A family headed by male is estimated to have higher count of family members than that of female. The estimated count also has positive association with the availability of bedrooms. However, as the house grow older, less people would like to stay there. Also, more family members like to accommodate in house having electricity. Greater income and food expenditure are also positively associated with number of family members. Beside it, if electricity interacts with income and type of family and influence the rate parameter.  

# Extention {#sec:Ext}

We will consider more appropirate models like Generalized poisson model, or Conway-Maxwell Poisson (COM-Poisson) Regression, which have less expected residual variance than the mean. We wil also attempt to apply quadratic model that address the slight curve in the deviance against fitted plot.  





