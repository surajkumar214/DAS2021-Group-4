---
title: "Group_04"
author: "Suraj Kumar"
date: "17/07/2021"
output: github_document 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, comment = NA)
```

```{r libraries}
#included all the necessary libraries

library(tidyverse) 
library(moderndive)
library(skimr)
library(kableExtra)
library(gridExtra)
library(GGally)
library(infer)
library(broom)
library(ggfortify)
library(jtools)
library(sjPlot)
library(AER)
library(car)
```



```{r data,echo=FALSE,eval=TRUE}
dataset4<-read.csv("/home/suraj/Desktop/stats_folder/group_04.csv")
dataset4<-dataset4%>%
  select(-Region)
dataset4[sapply(dataset4,is.character)]<-lapply(dataset4[sapply(dataset4,is.character)],as.factor)

dataset4$Electricity <-as.factor(dataset4$Electricity)
dataset4$Number.of.bedrooms <-as.factor(dataset4$Number.of.bedrooms)

```

# Introduction {#sec:Intro}
The Philippine government conducts surveys on household income and expenditure every three years to understand the living conditions of residents. In some past studies, we found that some factors may affect the number of family members. This research studied 2122 families in Soccsksargen district and collected the data of total household income, total food expenditure, household head sex, household head age, type of household, total number of family members, house floor area, house age, number of bedrooms and electricity, the purpose is to find the relationship between the number of family members and other variables. This report focuses on a different analysis level through summaries, boxplots, and general linear model. Section consists of an exploratory data analysis of number of family members and explores the potential relationship between member numbers and other variables. Section contains the results from fitting a generalized linear model to the data, as well as the assessment of the model assumptions. Concluding remarks are given in Section .


# Exploratory Data Analysis {#sec:EDA}
```{r exp}
table(dataset4$Household.Head.Sex,dataset4$Type.of.Household)
table(dataset4$Number.of.bedrooms,dataset4$Type.of.Household)
table(dataset4$Electricity,dataset4$Type.of.Household)
table(dataset4$Electricity,dataset4$Number.of.bedrooms)
table(dataset4$Household.Head.Sex,dataset4$Electricity)
```

# Formal Data Analysis {#sec:FDA}

we fit a poisson model as our response is a count variable. We have excluded Region as  a covariate because there was only one factor. 

```{r model1}

model1 <- glm(Total.Number.of.Family.members ~ 
                Household.Head.Sex                                                   +
                
                Household.Head.Age   *Type.of.Household                              +
                log(Total.Food.Expenditure ) * Type.of.Household                     +
                log(Total.Household.Income) * Type.of.Household                      +
                log(Total.Household.Income) * Electricity                            +
                Type.of.Household  *Electricity                                      +
                log(House.Floor.Area)                                                +
                Number.of.bedrooms                                                   +
                House.Age                                                           
                                                 
               ,data = dataset4,family = "poisson")  # fitted the poisson model using glm


resp <- resid(model1, type = "pearson")
resd <- resid(model1, type = "deviance")
p1<- ggplot(model1, aes(sample = resp)) + geom_point(stat = "qq", color = "#7fc97f") +
  ylab("Pearson residuals")
p2<- ggplot(model1, aes(sample = resd)) + geom_point(stat = "qq", color = "#7fc97f") +
  ylab("Deviance residuals")
p3<- ggplot(model1, aes(x = predict(model1, type="link"), y =resd))+
  geom_point(col = "#7fc97f") +
  ylab("Deviance residuals") + xlab("Linear predictor")
grid.arrange(p1, p2, p3, nrow = 1)  

c_d = cooks.distance(model1)
which.max(c_d)
i_n = influence(model1)$hat # calculate the influence of data points
which.max(i_n)

outlierTest(model1)
autoplot(model1,1:4)
```

 




```{r}
dataset4 <- dataset4[c(-2033,-1521),]

model1 <- glm(Total.Number.of.Family.members ~ 
                Household.Head.Sex                                                   +
                
                Household.Head.Age   *Type.of.Household                              +
                log(Total.Food.Expenditure ) * Type.of.Household                     +
                log(Total.Household.Income) * Type.of.Household                      +
                log(Total.Household.Income) * Electricity                            +
                Type.of.Household  *Electricity                                      +
                log(House.Floor.Area)                                                +
                Number.of.bedrooms                                                   +
                House.Age                                                           
                                                 
               ,data = dataset4,family = "poisson") 

autoplot(model1,which = 1:4)



resp <- resid(model1, type = "pearson")
resd <- resid(model1, type = "deviance")
p1<- ggplot(model1, aes(sample = resp)) + geom_point(stat = "qq", color = "#7fc97f") +
  ylab("Pearson residuals")
p2<- ggplot(model1, aes(sample = resd)) + geom_point(stat = "qq", color = "#7fc97f") +
  ylab("Deviance residuals")
p3<- ggplot(model1, aes(x = predict(model1, type="link"), y =resd))+
  geom_point(col = "#7fc97f") +
  ylab("Deviance residuals") + xlab("Linear predictor")
grid.arrange(p1, p2, p3, nrow = 1)
#check overdispersion


dispersiontest(model1, trafo = 1 ,alternative = c("less"))

#check overdispersion

ggplot(model1, aes(x=log(fitted(model1)), y=log((dataset4$Total.Number.of.Family.members-fitted(model1))^2)))+
  geom_point(col="#f46d43") +
  geom_abline(slope=1, intercept=0, col="#a6d96a", size=1) +
  ylab(expression((y-hat(mu))^2)) + xlab(expression(hat(mu)))
pred <- predict(model1, type = "response")
stand.resid <- rstandard(model = model1, type = "pearson") # Standardised Pearson residuals
par(mfrow=c(1,2))
plot(x = pred, y = stand.resid, xlab = "Predicted count", ylab = "Standardised Pearson residuals",
main = "Regular likelihood", ylim = c(-5,5))
abline(h = c(-3, -2, 0, 2, 3), lty = "dotted", col = "red")



```

```{r}
drop1(model1,test="F")

model2 <- glm(Total.Number.of.Family.members ~ 
                Household.Head.Sex                                                   +
                Household.Head.Age   *Type.of.Household                              +
                log(Total.Food.Expenditure ) * Type.of.Household                     +
                
                log(Total.Household.Income) * Electricity                            +
                Type.of.Household  *Electricity                                      +
                log(House.Floor.Area)                                                +
                House.Age                                                            +
                Number.of.bedrooms                                  
               ,data = dataset4,family = "poisson")  # fitted the poisson model using glm



outlierTest(model2)
autoplot(model2, which = 1:2)
```


```{r}
dataset4 <- dataset4[c(-262),]

model3 <- glm(Total.Number.of.Family.members ~ 
                Household.Head.Sex                                                   +
                Household.Head.Age   *Type.of.Household                              +
                log(Total.Food.Expenditure ) * Type.of.Household                     +
                
                log(Total.Household.Income) * Electricity                            +
                Type.of.Household  *Electricity                                      +
                log(House.Floor.Area)                                                +
                House.Age                                                            +
                Number.of.bedrooms                                  
               ,data = dataset4,family = "poisson")  # fitted the poisson model using glm

drop1(model3,test = "F")

model_fin  <- glm(Total.Number.of.Family.members ~ 
                Household.Head.Sex                                                   +
                Household.Head.Age                                                   +
                log(Total.Food.Expenditure ) * Type.of.Household                     +
                
                log(Total.Household.Income) * Electricity                            +
                Type.of.Household  *Electricity                                      +
                log(House.Floor.Area)                                                +
                House.Age                                                            +
                Number.of.bedrooms                                  
               ,data = dataset4,family = "poisson")  # fitted the poisson model using glm

resp <- resid(model_fin, type = "pearson")
resd <- resid(model_fin, type = "deviance")
p1<- ggplot(model_fin, aes(sample = resp)) + geom_point(stat = "qq", color = "#7fc97f") +
  ylab("Pearson residuals")
p2<- ggplot(model_fin, aes(sample = resd)) + geom_point(stat = "qq", color = "#7fc97f") +
  ylab("Deviance residuals")
p3<- ggplot(model_fin, aes(x = predict(model_fin, type="link"), y =resd))+
  geom_point(col = "#7fc97f") +
  ylab("Deviance residuals") + xlab("Linear predictor")

grid.arrange(p1, p2, p3, nrow = 1)

autoplot(model_fin, which = 1:4)

drop1(model_fin, test = "F")

X2 <- sum(resid(model_fin, type = "pearson")^2)
dp <- X2 / model_fin$df.res
dp
summary(model_fin, dispersion = dp)


```




# Conclusions {#sec:Conc}

# Extention {#sec:Ext}







